[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog where I share insights about AI research, software development, and the journey of building innovative products. Here you‚Äôll find technical deep-dives, project updates, and lessons learned along the way.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform\n\n\n\nAI\n\nResearch\n\nEducation\n\nOpen Source\n\n\n\n\n\n\n\n\n\nJan 16, 2025\n\n\nThe Fire Hacker\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "til/slm-optimization.html",
    "href": "til/slm-optimization.html",
    "title": "Optimizing SLMs for Edge Deployment",
    "section": "",
    "text": "Found that quantization with GGUF format can reduce model size by 75% while maintaining 95% accuracy for most tasks. This is game-changing for edge deployment!"
  },
  {
    "objectID": "til/slm-optimization.html#the-finding",
    "href": "til/slm-optimization.html#the-finding",
    "title": "Optimizing SLMs for Edge Deployment",
    "section": "",
    "text": "Found that quantization with GGUF format can reduce model size by 75% while maintaining 95% accuracy for most tasks. This is game-changing for edge deployment!"
  },
  {
    "objectID": "til/slm-optimization.html#quick-comparison",
    "href": "til/slm-optimization.html#quick-comparison",
    "title": "Optimizing SLMs for Edge Deployment",
    "section": "Quick Comparison",
    "text": "Quick Comparison\n\n\n\nModel\nOriginal Size\nGGUF Q4_K_M\nPerformance\n\n\n\n\nLlama 3.2 3B\n12 GB\n3 GB\n95%\n\n\nPhi-3 Mini\n7 GB\n1.8 GB\n93%\n\n\nMistral 7B\n28 GB\n7 GB\n94%"
  },
  {
    "objectID": "til/slm-optimization.html#how-to-quantize",
    "href": "til/slm-optimization.html#how-to-quantize",
    "title": "Optimizing SLMs for Edge Deployment",
    "section": "How to Quantize",
    "text": "How to Quantize\n# Install llama.cpp\ngit clone https://github.com/ggerganov/llama.cpp\ncd llama.cpp\nmake\n\n# Convert model to GGUF\npython convert.py model-path --outtype q4_k_m\n\n# Test inference speed\n./main -m model.gguf -p \"Test prompt\""
  },
  {
    "objectID": "til/slm-optimization.html#performance-tips",
    "href": "til/slm-optimization.html#performance-tips",
    "title": "Optimizing SLMs for Edge Deployment",
    "section": "Performance Tips",
    "text": "Performance Tips\n\nUse Q4_K_M: Best quality/size ratio\nEnable GPU layers: -ngl 32 for GPU acceleration\nAdjust context: Lower context = faster inference\nBatch processing: Process multiple inputs together"
  },
  {
    "objectID": "til/slm-optimization.html#real-world-impact",
    "href": "til/slm-optimization.html#real-world-impact",
    "title": "Optimizing SLMs for Edge Deployment",
    "section": "Real-World Impact",
    "text": "Real-World Impact\nOn M2 MacBook Air: - Before: 5 tokens/second with 7B model - After: 25 tokens/second with quantized version - RAM usage: Reduced from 14GB to 4GB\nThis makes local AI actually usable for production apps!"
  },
  {
    "objectID": "til/slm-optimization.html#tools",
    "href": "til/slm-optimization.html#tools",
    "title": "Optimizing SLMs for Edge Deployment",
    "section": "Tools",
    "text": "Tools\n\nllama.cpp\nOllama - Easy model management\nLM Studio - GUI for local models"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I‚Äôm passionate about democratizing AI and building tools that empower individuals and businesses to harness the power of artificial intelligence. My work focuses on making AI accessible, practical, and privacy-preserving.\n\n\n\n\nA revolutionary platform for creating and sharing AI-powered experiences in collaborative spaces. Think of it as Google Docs meets AI playground, where teams can work together with multiple AI models in real-time.\n\n\n\nSmall Language Models designed specifically for preserving and sharing memories through time. This project explores how we can use AI to create meaningful connections with our past and future selves.\n\n\n\n\n\n2025: Focused on AI research initiatives in distributed systems to build Efficient small models\n2024: BuildingBubblSpace: AI Pesronas with real time voice to voice capabiltiles to execute Enterprise Workflows\n2022: Founded AIEDX, focusing on local-first AI solutions\n\n\n\n\n\nSmall Language Models (SLMs): AI models that can run locally or small cluster of GPUs.\nDistributed Computing: Scaling AI across multiple nodes for both training and inference.\nAI-Frames: Open learning with the help of AI.\n\n\n\n\nI believe in giving back to the community. Check out my projects:\n\nTimeCapsule-SLM - Local-first memory preservation\n\n\n\n\n\n‚ÄúThe best AI is the one that runs on your device, respects your privacy, and enhances your capabilities without replacing your creativity.‚Äù\n\nI believe the future of AI is: - Local-first: Your data stays on your device - Collaborative: AI should enhance human collaboration - Accessible: Everyone should benefit from AI advances - Transparent: Understanding how AI makes decisions\n\n\n\nI love connecting with fellow developers, researchers, and AI enthusiasts. Feel free to reach out:\n\nGitHub: @thefirehacker\nX/Twitter: @thefirehacker\nEmail: firehacker@bubblspace.com\n\n\n\n\nI occasionally speak at conferences and write about AI, distributed systems, and building products. Some recent topics:\n\n‚ÄúSmall Models, Big Impact: The Future of Edge AI‚Äù\n‚ÄúBuilding Privacy-First AI Applications‚Äù\n‚ÄúFrom Research to Product: Shipping AI Features Users Love‚Äù\n\n\n\n\n\nüßô‚Äç‚ôÇÔ∏è The Fire Hacker wizard logo represents the magic of turning ideas into reality\nüî• I believe in ‚Äúhacking‚Äù in its original sense: creative problem-solving\nüåü My first program was a text-based adventure game\nüéØ Current goal: Make AI accessible to 1 million users\n\n\nWant to collaborate or just chat about AI? Drop me a message on X/Twitter or open an issue on one of my GitHub projects."
  },
  {
    "objectID": "about.html#founder-ai-researcher-at-aiedx",
    "href": "about.html#founder-ai-researcher-at-aiedx",
    "title": "About Me",
    "section": "",
    "text": "I‚Äôm passionate about democratizing AI and building tools that empower individuals and businesses to harness the power of artificial intelligence. My work focuses on making AI accessible, practical, and privacy-preserving.\n\n\n\n\nA revolutionary platform for creating and sharing AI-powered experiences in collaborative spaces. Think of it as Google Docs meets AI playground, where teams can work together with multiple AI models in real-time.\n\n\n\nSmall Language Models designed specifically for preserving and sharing memories through time. This project explores how we can use AI to create meaningful connections with our past and future selves.\n\n\n\n\n\n2025: Focused on AI research initiatives in distributed systems to build Efficient small models\n2024: BuildingBubblSpace: AI Pesronas with real time voice to voice capabiltiles to execute Enterprise Workflows\n2022: Founded AIEDX, focusing on local-first AI solutions\n\n\n\n\n\nSmall Language Models (SLMs): AI models that can run locally or small cluster of GPUs.\nDistributed Computing: Scaling AI across multiple nodes for both training and inference.\nAI-Frames: Open learning with the help of AI.\n\n\n\n\nI believe in giving back to the community. Check out my projects:\n\nTimeCapsule-SLM - Local-first memory preservation\n\n\n\n\n\n‚ÄúThe best AI is the one that runs on your device, respects your privacy, and enhances your capabilities without replacing your creativity.‚Äù\n\nI believe the future of AI is: - Local-first: Your data stays on your device - Collaborative: AI should enhance human collaboration - Accessible: Everyone should benefit from AI advances - Transparent: Understanding how AI makes decisions\n\n\n\nI love connecting with fellow developers, researchers, and AI enthusiasts. Feel free to reach out:\n\nGitHub: @thefirehacker\nX/Twitter: @thefirehacker\nEmail: firehacker@bubblspace.com\n\n\n\n\nI occasionally speak at conferences and write about AI, distributed systems, and building products. Some recent topics:\n\n‚ÄúSmall Models, Big Impact: The Future of Edge AI‚Äù\n‚ÄúBuilding Privacy-First AI Applications‚Äù\n‚ÄúFrom Research to Product: Shipping AI Features Users Love‚Äù\n\n\n\n\n\nüßô‚Äç‚ôÇÔ∏è The Fire Hacker wizard logo represents the magic of turning ideas into reality\nüî• I believe in ‚Äúhacking‚Äù in its original sense: creative problem-solving\nüåü My first program was a text-based adventure game\nüéØ Current goal: Make AI accessible to 1 million users\n\n\nWant to collaborate or just chat about AI? Drop me a message on X/Twitter or open an issue on one of my GitHub projects."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "The Fire Hacker",
    "section": "Recent Posts",
    "text": "Recent Posts\n\n\nGetting Started with TimeCapsule-SLM\nJanuary 2025 - Learn how to use the AI-powered research and learning platform that democratizes knowledge discovery. Read more ‚Üí"
  },
  {
    "objectID": "index.html#today-i-learned",
    "href": "index.html#today-i-learned",
    "title": "The Fire Hacker",
    "section": "Today I Learned",
    "text": "Today I Learned\n\n\nQuarto for Technical Blogging - Jupyter integration makes it perfect for data science blogging.\n\n\nOptimizing SLMs for Edge - GGUF quantization reduces model size by 75% with 95% accuracy.\n\n\nFirebase Real-time Sync - Offline persistence with conflict resolution for seamless sync."
  },
  {
    "objectID": "index.html#connect",
    "href": "index.html#connect",
    "title": "The Fire Hacker",
    "section": "Connect",
    "text": "Connect\n\nGitHub X/Twitter Contact"
  },
  {
    "objectID": "til.html",
    "href": "til.html",
    "title": "Today I Learned",
    "section": "",
    "text": "Quick notes and discoveries from my daily work with AI, software development, and research. These are bite-sized learnings that might save you time or spark new ideas.\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Quarto for Technical Blogging\n\n\n\n\n\n\nThe Fire Hacker\n\n\nSep 11, 2025\n\n\n\n\n\n\n\n\n\n\n\nOptimizing SLMs for Edge Deployment\n\n\n\n\n\n\nThe Fire Hacker\n\n\nSep 9, 2025\n\n\n\n\n\n\n\n\n\n\n\nFirebase Real-time Sync Patterns\n\n\n\n\n\n\nThe Fire Hacker\n\n\nSep 7, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/timecapsule-slm.html",
    "href": "blog/timecapsule-slm.html",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "",
    "text": "TimeCapsule-SLM is an innovative AI-powered research and learning platform that‚Äôs revolutionizing how we discover knowledge and collaborate on research. Built with privacy-first principles and cutting-edge AI technology, it democratizes access to powerful research tools while keeping your data secure and local."
  },
  {
    "objectID": "blog/timecapsule-slm.html#introduction",
    "href": "blog/timecapsule-slm.html#introduction",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "",
    "text": "TimeCapsule-SLM is an innovative AI-powered research and learning platform that‚Äôs revolutionizing how we discover knowledge and collaborate on research. Built with privacy-first principles and cutting-edge AI technology, it democratizes access to powerful research tools while keeping your data secure and local."
  },
  {
    "objectID": "blog/timecapsule-slm.html#what-is-timecapsule-slm",
    "href": "blog/timecapsule-slm.html#what-is-timecapsule-slm",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "What is TimeCapsule-SLM?",
    "text": "What is TimeCapsule-SLM?\nTimeCapsule-SLM combines the power of Small Language Models with advanced research capabilities to create a comprehensive platform for:\n\nResearchers seeking AI-assisted discovery and pattern recognition\nStudents looking for adaptive, personalized learning experiences\nTeachers creating interactive educational content\nTeams collaborating on knowledge discovery\n\nThe platform addresses critical challenges in modern education and research: - Research fragmentation across multiple sources - Inefficient learning workflows - Privacy concerns with cloud-based AI - Limited AI integration in educational settings - Resource constraints in low-bandwidth environments"
  },
  {
    "objectID": "blog/timecapsule-slm.html#core-features",
    "href": "blog/timecapsule-slm.html#core-features",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Core Features",
    "text": "Core Features\n\nüß† DeepResearch TimeCapsule\nTransform your research workflow with multi-agent AI collaboration:\n\nAI-Powered Discovery: Generate novel research ideas and hypotheses\nPattern Recognition: Uncover hidden connections in your data\nMulti-Agent System: Leverage specialized AI agents for different research tasks\nCollaborative Intelligence: Combine human expertise with AI insights\n\n\n\nüé• AI-Frames Interactive Learning\nCreate immersive, adaptive learning experiences:\n\nSequential Learning Paths: Build structured knowledge journeys\nMultimodal Content: Integrate videos, documents, and interactive elements\nAI-Guided Explanations: Get personalized help when you need it\nSelf-Paced Progress: Learn at your own speed with AI support\n\n\n\nüìö In-Browser RAG (Retrieval-Augmented Generation)\nExperience the power of semantic search without compromising privacy:\n\nLocal Vector Store: All processing happens in your browser\nOffline Capability: Works without internet after initial model load\nSemantic Understanding: Find information based on meaning, not just keywords\nPrivacy-First Design: Your documents never leave your device"
  },
  {
    "objectID": "blog/timecapsule-slm.html#getting-started",
    "href": "blog/timecapsule-slm.html#getting-started",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Getting Started",
    "text": "Getting Started\n\nPrerequisites\nBefore installing TimeCapsule-SLM, ensure you have:\n# Node.js 18 or higher\nnode --version\n\n# npm or yarn package manager\nnpm --version\n\n# Git for cloning the repository\ngit --version\n\n\nInstallation\n\nClone the Repository:\n\ngit clone https://github.com/thefirehacker/TimeCapsule-SLM.git\ncd TimeCapsule-SLM\n\nInstall Dependencies:\n\nnpm install\n# or\nyarn install\n\nConfigure Environment:\n\ncp env.example .env.local\nEdit .env.local to configure your AI providers:\n# Optional: Add API keys for cloud models\nOPENAI_API_KEY=your_key_here\n\n# Local model configuration (Ollama)\nOLLAMA_HOST=http://localhost:11434\n\nStart the Development Server:\n\nnpm run dev\n# or\nyarn dev\nVisit http://localhost:3000 to access TimeCapsule-SLM!"
  },
  {
    "objectID": "blog/timecapsule-slm.html#setting-up-local-ai-models",
    "href": "blog/timecapsule-slm.html#setting-up-local-ai-models",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Setting Up Local AI Models",
    "text": "Setting Up Local AI Models\nFor the best privacy and offline experience, use local models with Ollama:\n\nInstall Ollama\n# macOS/Linux\ncurl -fsSL https://ollama.ai/install.sh | sh\n\n# Windows - Download from ollama.ai\n\n\nPull Recommended Models\n# For research and general tasks\nollama pull gemma:2b\n\n# For code and technical content\nollama pull qwen2.5:3b\n\n# For creative writing\nollama pull llama3.2:3b"
  },
  {
    "objectID": "blog/timecapsule-slm.html#using-timecapsule-slm",
    "href": "blog/timecapsule-slm.html#using-timecapsule-slm",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Using TimeCapsule-SLM",
    "text": "Using TimeCapsule-SLM\n\nCreating Your First Research Project\n\nInitialize a Knowledge Base:\n\nClick ‚ÄúNew Project‚Äù\nChoose your domain (Research, Education, Personal)\nSelect your preferred AI model\n\nImport Your Documents:\n\nDrag and drop PDFs, Word docs, or text files\nThe system will automatically index and embed them\nAll processing happens locally in your browser\n\nStart Researching:\n\nUse natural language queries to explore your knowledge base\nThe AI will surface relevant information and suggest connections\nGenerate summaries, insights, and new research directions\n\n\n\n\nBuilding AI-Frames for Learning\nCreate interactive learning experiences with AI-Frames:\n// Example AI-Frame configuration\n{\n  \"title\": \"Introduction to Quantum Computing\",\n  \"modules\": [\n    {\n      \"type\": \"video\",\n      \"content\": \"intro-video.mp4\",\n      \"ai_notes\": true\n    },\n    {\n      \"type\": \"interactive\",\n      \"content\": \"qubit-simulator\",\n      \"ai_guidance\": \"adaptive\"\n    },\n    {\n      \"type\": \"quiz\",\n      \"ai_generated\": true,\n      \"difficulty\": \"progressive\"\n    }\n  ]\n}\n\n\nCollaborative Features\nTimeCapsule-SLM supports real-time collaboration:\n\nShared Workspaces: Invite team members to research projects\nLive AI Sessions: Collaborate with AI assistance in real-time\nKnowledge Graphs: Visualize connections discovered by your team\nVersion Control: Track changes and contributions"
  },
  {
    "objectID": "blog/timecapsule-slm.html#architecture-technology",
    "href": "blog/timecapsule-slm.html#architecture-technology",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Architecture & Technology",
    "text": "Architecture & Technology\nTimeCapsule-SLM is built with modern, performant technologies:\n\nFrontend: Next.js 15, React 19, TypeScript\nAI Integration: Support for Ollama, OpenAI, and local models\nDatabase: RxDB for offline-first data persistence\nVector Store: In-browser embeddings with WebAssembly\nAuthentication: NextAuth.js for secure access"
  },
  {
    "objectID": "blog/timecapsule-slm.html#privacy-security",
    "href": "blog/timecapsule-slm.html#privacy-security",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Privacy & Security",
    "text": "Privacy & Security\nYour privacy is our priority:\n\nLocal-First: All sensitive processing happens on your device\nNo Telemetry: We don‚Äôt track your usage or collect data\nOpen Source: Audit the code yourself (Apache 2.0 License)\nEncryption: Local data is encrypted at rest\nControl: You decide what stays local vs.¬†what uses cloud services"
  },
  {
    "objectID": "blog/timecapsule-slm.html#use-cases",
    "href": "blog/timecapsule-slm.html#use-cases",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Use Cases",
    "text": "Use Cases\n\nFor Researchers\n\nLiterature reviews with AI-powered synthesis\nPattern discovery in research data\nHypothesis generation and validation\nCollaborative paper writing\n\n\n\nFor Students\n\nPersonalized study guides\nAI tutoring for complex topics\nInteractive learning paths\nExam preparation with adaptive quizzes\n\n\n\nFor Teachers\n\nCreate engaging course content\nBuild interactive lessons\nTrack student progress\nGenerate assessments automatically\n\n\n\nFor Teams\n\nKnowledge management\nCollaborative research\nTraining materials\nDocumentation with AI assistance"
  },
  {
    "objectID": "blog/timecapsule-slm.html#performance-tips",
    "href": "blog/timecapsule-slm.html#performance-tips",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Performance Tips",
    "text": "Performance Tips\nOptimize TimeCapsule-SLM for your hardware:\n\nModel Selection: Choose smaller models (2-3B parameters) for faster responses\nCaching: Enable browser caching for repeated queries\nBatch Processing: Process multiple documents simultaneously\nGPU Acceleration: Use WebGPU when available for faster inference"
  },
  {
    "objectID": "blog/timecapsule-slm.html#roadmap-future-features",
    "href": "blog/timecapsule-slm.html#roadmap-future-features",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Roadmap & Future Features",
    "text": "Roadmap & Future Features\nWe‚Äôre constantly improving TimeCapsule-SLM:\n\nMobile Apps: iOS and Android applications (Q2 2025)\nVoice Interface: Natural conversation with your knowledge base\nAdvanced Visualizations: 3D knowledge graphs and mind maps\nPlugin System: Extend functionality with custom modules\nFederated Learning: Collaborate without sharing raw data"
  },
  {
    "objectID": "blog/timecapsule-slm.html#contributing",
    "href": "blog/timecapsule-slm.html#contributing",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Contributing",
    "text": "Contributing\nTimeCapsule-SLM is open source and welcomes contributions:\n# Fork the repository\n# Create a feature branch\ngit checkout -b feature/amazing-feature\n\n# Make your changes\n# Run tests\nnpm test\n\n# Submit a pull request\nCheck our contribution guidelines for more details."
  },
  {
    "objectID": "blog/timecapsule-slm.html#community-support",
    "href": "blog/timecapsule-slm.html#community-support",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Community & Support",
    "text": "Community & Support\nJoin our growing community:\n\nGitHub Discussions: Technical questions and feature requests\nDiscord Server: Real-time chat with developers and users\nDocumentation: Comprehensive guides at timecapsule.bubblspace.com\nX/Twitter: Follow @thefirehacker for updates"
  },
  {
    "objectID": "blog/timecapsule-slm.html#conclusion",
    "href": "blog/timecapsule-slm.html#conclusion",
    "title": "Getting Started with TimeCapsule-SLM: AI-Powered Research & Learning Platform",
    "section": "Conclusion",
    "text": "Conclusion\nTimeCapsule-SLM represents a new paradigm in AI-assisted research and learning. By combining powerful AI capabilities with privacy-first design and local-first architecture, we‚Äôre making advanced research tools accessible to everyone.\nWhether you‚Äôre a researcher pushing the boundaries of knowledge, a student seeking personalized learning, or a teacher creating engaging content, TimeCapsule-SLM empowers you to work smarter, not harder.\nStart your journey today and experience the future of AI-powered research and learning!\n\nReady to transform your research and learning workflow? Get started with TimeCapsule-SLM or visit timecapsule.bubblspace.com for more information.\nHave questions or feedback? Reach out on X/Twitter or open an issue on GitHub."
  },
  {
    "objectID": "til/firebase-sync.html",
    "href": "til/firebase-sync.html",
    "title": "Firebase Real-time Sync Patterns",
    "section": "",
    "text": "Learned about using Firebase‚Äôs offline persistence with conflict resolution for seamless sync. This pattern has saved me countless hours!"
  },
  {
    "objectID": "til/firebase-sync.html#the-pattern",
    "href": "til/firebase-sync.html#the-pattern",
    "title": "Firebase Real-time Sync Patterns",
    "section": "",
    "text": "Learned about using Firebase‚Äôs offline persistence with conflict resolution for seamless sync. This pattern has saved me countless hours!"
  },
  {
    "objectID": "til/firebase-sync.html#the-setup",
    "href": "til/firebase-sync.html#the-setup",
    "title": "Firebase Real-time Sync Patterns",
    "section": "The Setup",
    "text": "The Setup\n// Enable offline persistence\nimport { initializeApp } from 'firebase/app';\nimport { getFirestore, enableIndexedDbPersistence } from 'firebase/firestore';\n\nconst app = initializeApp(firebaseConfig);\nconst db = getFirestore(app);\n\n// Enable offline persistence\nenableIndexedDbPersistence(db)\n  .catch((err) =&gt; {\n    if (err.code == 'failed-precondition') {\n      // Multiple tabs open, persistence can only be enabled in one tab at a time.\n      console.log('Persistence failed');\n    } else if (err.code == 'unimplemented') {\n      // The current browser doesn't support persistence\n      console.log('Persistence not available');\n    }\n  });"
  },
  {
    "objectID": "til/firebase-sync.html#conflict-resolution-strategy",
    "href": "til/firebase-sync.html#conflict-resolution-strategy",
    "title": "Firebase Real-time Sync Patterns",
    "section": "Conflict Resolution Strategy",
    "text": "Conflict Resolution Strategy\nclass SyncManager {\n  constructor() {\n    this.pendingWrites = new Map();\n  }\n\n  async syncDocument(docRef, data) {\n    const docId = docRef.id;\n    \n    try {\n      // Optimistic update\n      this.pendingWrites.set(docId, data);\n      \n      // Try to sync\n      await docRef.set({\n        ...data,\n        lastModified: serverTimestamp(),\n        deviceId: getDeviceId()\n      }, { merge: true });\n      \n      // Success - clear pending\n      this.pendingWrites.delete(docId);\n      \n    } catch (error) {\n      // Conflict detected\n      if (error.code === 'unavailable') {\n        // We're offline, it will sync when back online\n        console.log('Will sync when online');\n      } else {\n        // Real conflict, need resolution\n        await this.resolveConflict(docRef, data);\n      }\n    }\n  }\n  \n  async resolveConflict(docRef, localData) {\n    const serverData = await docRef.get();\n    \n    // Simple last-write-wins\n    if (localData.timestamp &gt; serverData.data().timestamp) {\n      await docRef.set(localData);\n    }\n    // Could implement more complex strategies here\n  }\n}"
  },
  {
    "objectID": "til/firebase-sync.html#key-insights",
    "href": "til/firebase-sync.html#key-insights",
    "title": "Firebase Real-time Sync Patterns",
    "section": "Key Insights",
    "text": "Key Insights\n\nAlways use merge: true for partial updates\nTrack pending writes for UI feedback\nUse transactions for critical updates\nImplement retry logic with exponential backoff"
  },
  {
    "objectID": "til/firebase-sync.html#gotchas",
    "href": "til/firebase-sync.html#gotchas",
    "title": "Firebase Real-time Sync Patterns",
    "section": "Gotchas",
    "text": "Gotchas\n\nOffline persistence doesn‚Äôt work with multiple tabs\nLarge documents (&gt;1MB) can cause sync issues\nDeeply nested updates might not trigger listeners"
  },
  {
    "objectID": "til/firebase-sync.html#performance-win",
    "href": "til/firebase-sync.html#performance-win",
    "title": "Firebase Real-time Sync Patterns",
    "section": "Performance Win",
    "text": "Performance Win\nBefore: 300ms latency for each write After: Instant UI updates with background sync\nUser experience improved dramatically! üöÄ"
  },
  {
    "objectID": "til/quarto-blogging.html",
    "href": "til/quarto-blogging.html",
    "title": "Using Quarto for Technical Blogging",
    "section": "",
    "text": "Just discovered that Quarto‚Äôs integration with Jupyter notebooks makes it perfect for data science blogging. You can execute code blocks during the build process!"
  },
  {
    "objectID": "til/quarto-blogging.html#the-discovery",
    "href": "til/quarto-blogging.html#the-discovery",
    "title": "Using Quarto for Technical Blogging",
    "section": "",
    "text": "Just discovered that Quarto‚Äôs integration with Jupyter notebooks makes it perfect for data science blogging. You can execute code blocks during the build process!"
  },
  {
    "objectID": "til/quarto-blogging.html#example",
    "href": "til/quarto-blogging.html#example",
    "title": "Using Quarto for Technical Blogging",
    "section": "Example",
    "text": "Example\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate data\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\n# Create plot\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, 'b-', linewidth=2)\nplt.title('Sine Wave')\nplt.grid(True, alpha=0.3)\nplt.show()"
  },
  {
    "objectID": "til/quarto-blogging.html#key-features",
    "href": "til/quarto-blogging.html#key-features",
    "title": "Using Quarto for Technical Blogging",
    "section": "Key Features",
    "text": "Key Features\n\nLive code execution: Code runs during site build\nMultiple languages: Python, R, Julia, Observable JS\nCache results: Don‚Äôt re-run expensive computations\nInteractive widgets: Embed Plotly, Bokeh, etc."
  },
  {
    "objectID": "til/quarto-blogging.html#configuration-tip",
    "href": "til/quarto-blogging.html#configuration-tip",
    "title": "Using Quarto for Technical Blogging",
    "section": "Configuration Tip",
    "text": "Configuration Tip\nAdd this to your _quarto.yml for better code highlighting:\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-copy: true\nNow readers can toggle code visibility and copy snippets easily!"
  },
  {
    "objectID": "til/quarto-blogging.html#resources",
    "href": "til/quarto-blogging.html#resources",
    "title": "Using Quarto for Technical Blogging",
    "section": "Resources",
    "text": "Resources\n\nQuarto Documentation\nQuarto Gallery"
  }
]