<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="The Fire Hacker">
<meta name="dcterms.date" content="2025-01-16">

<title>My First CUDA Kernel: Learning GPU Programming from Scratch – The Fire Hacker</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../assets/favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-665a47377fd1fb2966ef7e6e7341ee54.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V1B8R98P79"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-V1B8R98P79', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">The Fire Hacker</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../til.html"> 
<span class="menu-text">Today I Learned</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/thefirehacker"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/thefirehacker"> <i class="bi bi-twitter" role="img" aria-label="X (Twitter)">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-beginning-why-learn-cuda" id="toc-the-beginning-why-learn-cuda" class="nav-link active" data-scroll-target="#the-beginning-why-learn-cuda">The Beginning: Why Learn CUDA?</a></li>
  <li><a href="#the-program-overall-architecture" id="toc-the-program-overall-architecture" class="nav-link" data-scroll-target="#the-program-overall-architecture">The Program: Overall Architecture</a>
  <ul class="collapse">
  <li><a href="#file-structure-purpose" id="toc-file-structure-purpose" class="nav-link" data-scroll-target="#file-structure-purpose">File Structure &amp; Purpose</a></li>
  </ul></li>
  <li><a href="#the-challenge-what-was-i-trying-to-achieve" id="toc-the-challenge-what-was-i-trying-to-achieve" class="nav-link" data-scroll-target="#the-challenge-what-was-i-trying-to-achieve">The Challenge: What Was I Trying to Achieve?</a></li>
  <li><a href="#the-big-picture-how-gpus-think-differently" id="toc-the-big-picture-how-gpus-think-differently" class="nav-link" data-scroll-target="#the-big-picture-how-gpus-think-differently">The Big Picture: How GPUs Think Differently</a></li>
  <li><a href="#setting-up-the-journey-to-hello-gpu" id="toc-setting-up-the-journey-to-hello-gpu" class="nav-link" data-scroll-target="#setting-up-the-journey-to-hello-gpu">Setting Up: The Journey to “Hello GPU”</a>
  <ul class="collapse">
  <li><a href="#step-1-install-cuda-toolkit" id="toc-step-1-install-cuda-toolkit" class="nav-link" data-scroll-target="#step-1-install-cuda-toolkit">Step 1: Install CUDA Toolkit</a></li>
  <li><a href="#step-2-pytorch-with-cuda-support" id="toc-step-2-pytorch-with-cuda-support" class="nav-link" data-scroll-target="#step-2-pytorch-with-cuda-support">Step 2: PyTorch with CUDA Support</a></li>
  </ul></li>
  <li><a href="#the-code-understanding-every-line" id="toc-the-code-understanding-every-line" class="nav-link" data-scroll-target="#the-code-understanding-every-line">The Code: Understanding Every Line</a>
  <ul class="collapse">
  <li><a href="#the-gpu-kernel-where-the-magic-happens" id="toc-the-gpu-kernel-where-the-magic-happens" class="nav-link" data-scroll-target="#the-gpu-kernel-where-the-magic-happens">The GPU Kernel: Where the Magic Happens</a></li>
  <li><a href="#launching-the-kernel-mission-control" id="toc-launching-the-kernel-mission-control" class="nav-link" data-scroll-target="#launching-the-kernel-mission-control">Launching the Kernel: Mission Control</a></li>
  <li><a href="#the-python-bridge-making-it-usable" id="toc-the-python-bridge-making-it-usable" class="nav-link" data-scroll-target="#the-python-bridge-making-it-usable">The Python Bridge: Making it Usable</a></li>
  </ul></li>
  <li><a href="#the-benchmarking-measuring-reality" id="toc-the-benchmarking-measuring-reality" class="nav-link" data-scroll-target="#the-benchmarking-measuring-reality">The Benchmarking: Measuring Reality</a>
  <ul class="collapse">
  <li><a href="#timing-gpu-code-its-tricky" id="toc-timing-gpu-code-its-tricky" class="nav-link" data-scroll-target="#timing-gpu-code-its-tricky">Timing GPU Code: It’s Tricky!</a></li>
  </ul></li>
  <li><a href="#the-results-what-i-learned-from-the-numbers" id="toc-the-results-what-i-learned-from-the-numbers" class="nav-link" data-scroll-target="#the-results-what-i-learned-from-the-numbers">The Results: What I Learned from the Numbers</a>
  <ul class="collapse">
  <li><a href="#the-mystery-of-the-slow-16384" id="toc-the-mystery-of-the-slow-16384" class="nav-link" data-scroll-target="#the-mystery-of-the-slow-16384">The Mystery of the Slow 16384</a></li>
  <li><a href="#memory-bandwidth-the-real-bottleneck" id="toc-memory-bandwidth-the-real-bottleneck" class="nav-link" data-scroll-target="#memory-bandwidth-the-real-bottleneck">Memory Bandwidth: The Real Bottleneck</a></li>
  </ul></li>
  <li><a href="#the-revelations-what-changed-my-understanding" id="toc-the-revelations-what-changed-my-understanding" class="nav-link" data-scroll-target="#the-revelations-what-changed-my-understanding">The Revelations: What Changed My Understanding</a></li>
  <li><a href="#whats-next" id="toc-whats-next" class="nav-link" data-scroll-target="#whats-next">What’s Next?</a></li>
  <li><a href="#resources-that-helped-me" id="toc-resources-that-helped-me" class="nav-link" data-scroll-target="#resources-that-helped-me">Resources That Helped Me</a></li>
  <li><a href="#the-journey-continues" id="toc-the-journey-continues" class="nav-link" data-scroll-target="#the-journey-continues">The Journey Continues</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">My First CUDA Kernel: Learning GPU Programming from Scratch</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>The Fire Hacker </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 16, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="the-beginning-why-learn-cuda" class="level2">
<h2 class="anchored" data-anchor-id="the-beginning-why-learn-cuda">The Beginning: Why Learn CUDA?</h2>
<p>Today I ran my first custom GPU code! Along with distributed pre-training AI models, I wanted to understand what’s happening at the low level. I was looking for a good resource to learn about kernel development for both inference &amp; training. My interests were in MoE routing kernels, however I decided to start simple: compile and run kernels on local GPUs. I have a few gaming laptops and decided to run kernels on them.</p>
<p>I decided to start with the simplest possible program: adding two vectors together. GPU Mode’s reference kernels are perfect to build a working end-to-end workflow.</p>
</section>
<section id="the-program-overall-architecture" class="level2">
<h2 class="anchored" data-anchor-id="the-program-overall-architecture">The Program: Overall Architecture</h2>
<p>Before diving into the details, let me explain the complete program flow. We’ll be working with the <a href="https://github.com/thefirehacker/reference-kernels/tree/main/problems/pmpp/vectoradd_py"><code>vectoradd_py</code> problem</a> from the reference-kernels repository.</p>
<section id="file-structure-purpose" class="level3">
<h3 class="anchored" data-anchor-id="file-structure-purpose">File Structure &amp; Purpose</h3>
<pre><code>problems/pmpp/vectoradd_py/
├── run_local.py        # Main benchmark script
├── submission.py       # Our custom CUDA kernel implementation
├── reference.py        # Correctness checking
├── task.py            # Data structure definitions
└── README.md          # Problem description</code></pre>
<p><strong>The Execution Flow:</strong></p>
<ol type="1">
<li><strong><code>run_local.py</code></strong> - The orchestrator that:
<ul>
<li>Generates test data of various sizes</li>
<li>Calls our custom kernel</li>
<li>Measures performance with CUDA events</li>
<li>Verifies correctness against reference implementation</li>
</ul></li>
<li><strong><code>submission.py</code></strong> - Contains our CUDA kernel using PyTorch’s inline compilation:
<ul>
<li>CUDA C++ code written as Python strings</li>
<li>Compiled on-the-fly using <code>load_inline</code></li>
<li>Creates a Python module we can call</li>
</ul></li>
<li><strong>The Magic: JIT Compilation Process</strong></li>
</ol>
<p>When we use <code>torch.utils.cpp_extension.load_inline</code>, here’s what happens behind the scenes:</p>
<pre><code>Your Python Code
        ↓
torch.utils.cpp_extension.load_inline
        ↓
Generates .cpp and .cu source files
        ↓
Writes build.ninja file
        ↓
ninja → nvcc/g++ compile → add_cuda.so
        ↓
dlopen() loads .so into Python process</code></pre>
<p>This is <strong>ahead-of-time compilation</strong> - once compiled, your kernel is fixed machine code running directly on the GPU!</p>
</section>
</section>
<section id="the-challenge-what-was-i-trying-to-achieve" class="level2">
<h2 class="anchored" data-anchor-id="the-challenge-what-was-i-trying-to-achieve">The Challenge: What Was I Trying to Achieve?</h2>
<p>My goal was simple but specific: 1. Write actual CUDA code that runs on my RTX 2050 laptop GPU 2. Understand how thousands of threads work together 3. Measure real performance and understand the numbers 4. Learn why GPUs are so powerful for AI workloads</p>
<p>I found the perfect learning resource which I modified for my use: <a href="https://github.com/thefirehacker/reference-kernels">GPU Mode’s reference-kernels repository fork</a>. It’s a collection of progressively harder GPU programming challenges, starting with vector addition.</p>
</section>
<section id="the-big-picture-how-gpus-think-differently" class="level2">
<h2 class="anchored" data-anchor-id="the-big-picture-how-gpus-think-differently">The Big Picture: How GPUs Think Differently</h2>
<p>Before diving into code, here’s the mental shift that changed everything for me:</p>
<p><strong>CPU Thinking</strong>: “Do step 1, then step 2, then step 3…” <strong>GPU Thinking</strong>: “Do ALL the steps at once, everywhere!”</p>
<p>Imagine you need to paint 1000 fence posts. A CPU is like one very fast painter who paints each post perfectly, one after another. A GPU is like hiring 1000 amateur painters who each paint one post simultaneously. Even if each painter is slower, getting all posts done at once is way faster!</p>
<p>For vector addition (C = A + B), instead of:</p>
<pre><code>for i in range(million):
    C[i] = A[i] + B[i]  # One at a time</code></pre>
<p>The GPU does:</p>
<pre><code>Thread 0: C[0] = A[0] + B[0]
Thread 1: C[1] = A[1] + B[1]
Thread 2: C[2] = A[2] + B[2]
... (all at the same time!)
Thread 999999: C[999999] = A[999999] + B[999999]</code></pre>
</section>
<section id="setting-up-the-journey-to-hello-gpu" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-the-journey-to-hello-gpu">Setting Up: The Journey to “Hello GPU”</h2>
<p>Getting CUDA working on Windows with WSL2 was an adventure. Here’s what actually worked:</p>
<section id="step-1-install-cuda-toolkit" class="level3">
<h3 class="anchored" data-anchor-id="step-1-install-cuda-toolkit">Step 1: Install CUDA Toolkit</h3>
<p>First, I needed the CUDA compiler (<code>nvcc</code>) to turn my code into GPU instructions:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get NVIDIA's official CUDA repository</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> dpkg <span class="at">-i</span> cuda-keyring_1.1-1_all.deb</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt-get update</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt-get install <span class="at">-y</span> cuda-toolkit-12-1</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Tell the system where CUDA lives</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">CUDA_HOME</span><span class="op">=</span>/usr/local/cuda-12.1</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">PATH</span><span class="op">=</span><span class="va">$CUDA_HOME</span>/bin:<span class="va">$PATH</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="step-2-pytorch-with-cuda-support" class="level3">
<h3 class="anchored" data-anchor-id="step-2-pytorch-with-cuda-support">Step 2: PyTorch with CUDA Support</h3>
<p>PyTorch makes it easy to compile CUDA code on-the-fly:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">--index-url</span> https://download.pytorch.org/whl/cu121 torch</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
</section>
<section id="the-code-understanding-every-line" class="level2">
<h2 class="anchored" data-anchor-id="the-code-understanding-every-line">The Code: Understanding Every Line</h2>
<p>Now for the exciting part - the actual GPU code! Let me explain what each piece does and why it matters.</p>
<section id="the-gpu-kernel-where-the-magic-happens" class="level3">
<h3 class="anchored" data-anchor-id="the-gpu-kernel-where-the-magic-happens">The GPU Kernel: Where the Magic Happens</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">template</span> <span class="op">&lt;</span><span class="kw">typename</span> <span class="dt">scalar_t</span><span class="op">&gt;</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> add_kernel<span class="op">(</span><span class="at">const</span> <span class="dt">scalar_t</span><span class="op">*</span> <span class="ex">__restrict__</span> A<span class="op">,</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                           <span class="at">const</span> <span class="dt">scalar_t</span><span class="op">*</span> <span class="ex">__restrict__</span> B<span class="op">,</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                           <span class="dt">scalar_t</span><span class="op">*</span> <span class="ex">__restrict__</span> C<span class="op">,</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                           <span class="dt">int</span> N<span class="op">)</span> <span class="op">{</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Who am I? Calculate my unique ID among thousands of threads</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> idx <span class="op">=</span> blockIdx<span class="op">.</span>x <span class="op">*</span> blockDim<span class="op">.</span>x <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Am I responsible for a valid element?</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>idx <span class="op">&lt;</span> N<span class="op">)</span> <span class="op">{</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        C<span class="op">[</span>idx<span class="op">]</span> <span class="op">=</span> A<span class="op">[</span>idx<span class="op">]</span> <span class="op">+</span> B<span class="op">[</span>idx<span class="op">];</span>  <span class="co">// Do my one simple job</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>What’s happening here:</strong></p>
<ul>
<li><p><strong><code>__global__</code></strong>: This function runs on the GPU. It’s called from the CPU but executes on thousands of GPU cores simultaneously.</p></li>
<li><p><strong>Thread Identity Crisis (solved!)</strong>: Each thread needs to know which element to process. Think of it like a massive factory where each worker needs to know which item on the conveyor belt is theirs:</p>
<ul>
<li><code>threadIdx.x</code>: “I’m worker #5 in my team”</li>
<li><code>blockIdx.x</code>: “My team is team #3”</li>
<li><code>blockDim.x</code>: “Each team has 256 workers”</li>
<li>So my global position is: <code>3 * 256 + 5 = 773</code> - I handle element 773!</li>
</ul></li>
<li><p><strong><code>if (idx &lt; N)</code></strong>: Safety first! We might launch more threads than we have data (for efficiency reasons), so each thread checks if it has real work to do.</p></li>
</ul>
</section>
<section id="launching-the-kernel-mission-control" class="level3">
<h3 class="anchored" data-anchor-id="launching-the-kernel-mission-control">Launching the Kernel: Mission Control</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>torch<span class="op">::</span>Tensor add_cuda<span class="op">(</span>torch<span class="op">::</span>Tensor A<span class="op">,</span> torch<span class="op">::</span>Tensor B<span class="op">)</span> <span class="op">{</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> N <span class="op">=</span> A<span class="op">.</span>numel<span class="op">();</span>  <span class="co">// How many elements total?</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">auto</span> C <span class="op">=</span> torch<span class="op">::</span>empty_like<span class="op">(</span>A<span class="op">);</span>  <span class="co">// Prepare output space</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Configure the thread army</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">int</span> threads <span class="op">=</span> <span class="dv">256</span><span class="op">;</span>  <span class="co">// Threads per block (team size)</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">const</span> <span class="dt">int</span> blocks <span class="op">=</span> <span class="op">(</span>N <span class="op">+</span> threads <span class="op">-</span> <span class="dv">1</span><span class="op">)</span> <span class="op">/</span> threads<span class="op">;</span>  <span class="co">// How many teams needed?</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">// LAUNCH! Send thousands of threads to work</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    add_kernel<span class="op">&lt;</span><span class="dt">scalar_t</span><span class="op">&gt;&lt;&lt;&lt;</span>blocks<span class="op">,</span> threads<span class="op">&gt;&gt;&gt;(</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        A<span class="op">.</span>data_ptr<span class="op">&lt;</span><span class="dt">scalar_t</span><span class="op">&gt;(),</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        B<span class="op">.</span>data_ptr<span class="op">&lt;</span><span class="dt">scalar_t</span><span class="op">&gt;(),</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        C<span class="op">.</span>data_ptr<span class="op">&lt;</span><span class="dt">scalar_t</span><span class="op">&gt;(),</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        N</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="op">);</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>The Strategy:</strong> - We organize threads into blocks (teams) of 256 threads each - Why 256? It’s a multiple of 32 (warp size - the GPU’s natural execution unit) - The <code>&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;</code> syntax is CUDA’s special way to say “launch this many blocks with this many threads each”</p>
</section>
<section id="the-python-bridge-making-it-usable" class="level3">
<h3 class="anchored" data-anchor-id="the-python-bridge-making-it-usable">The Python Bridge: Making it Usable</h3>
<p>PyTorch’s <code>load_inline</code> is brilliant - it compiles CUDA code on-the-fly:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>add_module <span class="op">=</span> load_inline(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    name<span class="op">=</span><span class="st">'add_cuda'</span>,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    cpp_sources<span class="op">=</span>add_cpp_source,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    cuda_sources<span class="op">=</span>add_cuda_source,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    functions<span class="op">=</span>[<span class="st">'add_cuda'</span>],</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="va">True</span>,  <span class="co"># Show me what's happening!</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>First time you run this, you’ll see:</p>
<pre><code>Detected CUDA files, patching ldflags
Building extension module add_cuda...
ninja: no work to do.
Loading extension module add_cuda...</code></pre>
<p>That’s <code>nvcc</code> compiling your GPU code into a Python module!</p>
</section>
</section>
<section id="the-benchmarking-measuring-reality" class="level2">
<h2 class="anchored" data-anchor-id="the-benchmarking-measuring-reality">The Benchmarking: Measuring Reality</h2>
<p>The <code>run_local.py</code> script does something clever - it automatically picks test sizes based on available GPU memory:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># How much GPU memory is free?</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>free_bytes, _ <span class="op">=</span> torch.cuda.mem_get_info()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>budget <span class="op">=</span> <span class="bu">int</span>(free_bytes <span class="op">*</span> <span class="fl">0.8</span>)  <span class="co"># Use 80% to be safe</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># For 2D matrices: need space for A, B, and C</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>s_max <span class="op">=</span> <span class="bu">int</span>(math.sqrt(budget <span class="op">/</span> (<span class="dv">3</span> <span class="op">*</span> bytes_per_elem)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This prevents the dreaded “CUDA out of memory” error!</p>
<section id="timing-gpu-code-its-tricky" class="level3">
<h3 class="anchored" data-anchor-id="timing-gpu-code-its-tricky">Timing GPU Code: It’s Tricky!</h3>
<p>You can’t use regular Python timing for GPU code because GPU operations are asynchronous. The solution? CUDA Events:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>t0 <span class="op">=</span> torch.cuda.Event(enable_timing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> torch.cuda.Event(enable_timing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>t0.record()              <span class="co"># Start timer ON THE GPU</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>custom_kernel(case)      <span class="co"># Run kernel</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>t1.record()              <span class="co"># Stop timer ON THE GPU</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>torch.cuda.synchronize() <span class="co"># Wait for GPU to finish</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>elapsed <span class="op">=</span> t0.elapsed_time(t1)  <span class="co"># Get time in milliseconds</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
</section>
<section id="the-results-what-i-learned-from-the-numbers" class="level2">
<h2 class="anchored" data-anchor-id="the-results-what-i-learned-from-the-numbers">The Results: What I Learned from the Numbers</h2>
<p>Running on my RTX 2050 (4GB VRAM):</p>
<pre><code>size=4096:  mean=0.9877 ms    (67 million elements)
size=8192:  mean=3.8027 ms    (268 million elements)
size=12288: mean=8.5460 ms    (603 million elements)
size=16384: mean=150.3063 ms  (1.07 billion elements) ← WHAT?!</code></pre>
<section id="the-mystery-of-the-slow-16384" class="level3">
<h3 class="anchored" data-anchor-id="the-mystery-of-the-slow-16384">The Mystery of the Slow 16384</h3>
<p>Why did 16384×16384 suddenly become 17x slower? This taught me a crucial lesson about GPU architecture:</p>
<p><strong>The Problem</strong>: With 256 threads per block, processing 268,435,456 elements needs <strong>1,048,576 blocks</strong>!</p>
<p>The GPU scheduler choked trying to manage over a million tiny work units. It’s like trying to manage a million separate construction crews for a project - the coordination overhead kills you!</p>
<p><strong>The Solution</strong>: Grid-stride loops - have each thread process multiple elements:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> idx <span class="op">=</span> blockIdx<span class="op">.</span>x <span class="op">*</span> blockDim<span class="op">.</span>x <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>     idx <span class="op">&lt;</span> N<span class="op">;</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>     idx <span class="op">+=</span> blockDim<span class="op">.</span>x <span class="op">*</span> gridDim<span class="op">.</span>x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    C<span class="op">[</span>idx<span class="op">]</span> <span class="op">=</span> A<span class="op">[</span>idx<span class="op">]</span> <span class="op">+</span> B<span class="op">[</span>idx<span class="op">];</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Now you can cap blocks at a reasonable number (like 10,000) and each thread handles multiple elements.</p>
</section>
<section id="memory-bandwidth-the-real-bottleneck" class="level3">
<h3 class="anchored" data-anchor-id="memory-bandwidth-the-real-bottleneck">Memory Bandwidth: The Real Bottleneck</h3>
<p>For the 8192×8192 case: - Data moved: 268M elements × 2 bytes × 3 arrays = 1.6 GB - Time: 3.8 ms - Bandwidth: 421 GB/s</p>
<p>My RTX 2050’s theoretical max is ~200 GB/s, so we’re doing great! Wait, how are we exceeding theoretical max? Cache! Some data gets reused from the GPU’s L2 cache.</p>
</section>
</section>
<section id="the-revelations-what-changed-my-understanding" class="level2">
<h2 class="anchored" data-anchor-id="the-revelations-what-changed-my-understanding">The Revelations: What Changed My Understanding</h2>
<ol type="1">
<li><p><strong>GPUs are not fast CPUs</strong> - They’re a completely different beast. They’re terrible at complex branching logic but amazing at doing the same simple thing everywhere.</p></li>
<li><p><strong>Memory movement dominates</strong> - For simple operations like addition, you spend more time moving data than computing. This is why AI models use operations like matrix multiplication that do lots of compute per memory access.</p></li>
<li><p><strong>Launch configuration matters hugely</strong> - Too many blocks? Scheduling overhead. Too few? Underutilization. It’s an art.</p></li>
<li><p><strong>The power of parallel thinking</strong> - Once you start thinking “what can happen simultaneously?” instead of “what comes next?”, you see opportunities everywhere.</p></li>
</ol>
</section>
<section id="whats-next" class="level2">
<h2 class="anchored" data-anchor-id="whats-next">What’s Next?</h2>
<p>Now that I’ve got basic kernels working, I’m excited to explore: - <strong>Shared memory</strong>: Using the 48KB of ultra-fast memory shared within each block - <strong>Warp-level operations</strong>: Leveraging the fact that 32 threads execute in lockstep - <strong>Reduction operations</strong>: How do you sum a billion numbers in parallel? - <strong>Matrix multiplication</strong>: The operation that powers all of deep learning</p>
</section>
<section id="resources-that-helped-me" class="level2">
<h2 class="anchored" data-anchor-id="resources-that-helped-me">Resources That Helped Me</h2>
<ul>
<li><strong><a href="https://github.com/thefirehacker/reference-kernels">Reference Kernels Repo</a></strong>: Practice problems with increasing difficulty</li>
<li><strong><a href="http://www.wen-mei-hwu.com/">PMPP Book</a></strong>: “Programming Massively Parallel Processors” - The theory behind it all</li>
<li><strong><a href="https://discord.gg/gpumode">GPU Mode Discord</a></strong>: Amazing community of people learning together</li>
<li><strong><a href="https://docs.nvidia.com/cuda/">CUDA Documentation</a></strong>: Surprisingly readable once you know the basics</li>
</ul>
</section>
<section id="the-journey-continues" class="level2">
<h2 class="anchored" data-anchor-id="the-journey-continues">The Journey Continues</h2>
<p>Starting with vector addition might seem trivial, but it opened the door to understanding how modern AI actually works at the hardware level. Every transformer model, every diffusion model, every neural network - they’re all built on these fundamental parallel operations.</p>
<p>The moment it clicked that my GPU was running 65,536 threads simultaneously, each doing their tiny part of the work, was magical. It’s not just faster computing - it’s a fundamentally different way of solving problems.</p>
<p>Next week: I’m going to tackle matrix multiplication and see if I can beat PyTorch’s built-in implementation (spoiler: probably not, but I’ll learn tons trying!).</p>
<hr>
<p><em>Want to try this yourself? Clone the <a href="https://github.com/thefirehacker/reference-kernels">reference-kernels repo</a> and start with <code>problems/pmpp/vectoradd_py/</code>. The journey from CPU thinking to GPU thinking is worth it!</em></p>


</section>

</main> <!-- /main -->
<!-- Enhanced Google Analytics 4 Implementation for The Fire Hacker -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V1B8R98P79"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  
  // Initialize GA4 with enhanced configuration
  gtag('js', new Date());
  gtag('config', 'G-V1B8R98P79', {
    // Enhanced ecommerce and engagement tracking
    send_page_view: true,
    page_title: document.title,
    page_location: window.location.href,
    
    // Enhanced measurement features
    enhanced_measurement: {
      scrolls: true,
      outbound_clicks: true,
      site_search: true,
      video_engagement: true,
      file_downloads: true
    },
    
    // Custom parameters for The Fire Hacker
    custom_map: {
      'dimension1': 'page_type',
      'dimension2': 'content_category',
      'dimension3': 'user_engagement_level'
    },
    
    // Debug mode (remove in production if needed)
    debug_mode: false
  });

  // Set custom dimensions based on page
  const pageType = window.location.pathname.includes('/blog/') ? 'blog_post' :
                   window.location.pathname.includes('/til/') ? 'til_post' :
                   window.location.pathname === '/' || window.location.pathname === '/index.html' ? 'homepage' :
                   window.location.pathname.includes('/about') ? 'about' :
                   'other';

  const contentCategory = window.location.pathname.includes('/blog/') ? 'blog' :
                         window.location.pathname.includes('/til/') ? 'today_i_learned' :
                         'main_site';

  // Send custom dimensions
  gtag('config', 'G-V1B8R98P79', {
    'custom_map.dimension1': pageType,
    'custom_map.dimension2': contentCategory
  });

  // Enhanced page view with custom parameters
  gtag('event', 'page_view', {
    'page_type': pageType,
    'content_category': contentCategory,
    'site_name': 'The Fire Hacker',
    'author': 'Fire Hacker',
    'contact_email': 'firehacker@bubblspace.com'
  });

  // Track mailto clicks to firehacker@bubblspace.com
  document.addEventListener('DOMContentLoaded', function() {
    document.querySelectorAll('a[href^="mailto:firehacker@bubblspace.com"]').forEach(function(link) {
      link.addEventListener('click', function() {
        gtag('event', 'email_contact', {
          'contact_email': 'firehacker@bubblspace.com',
          'contact_method': 'mailto_link'
        });
      });
    });
  });
</script>

<!-- Load enhanced tracking script -->
<script src="analytics.js"></script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>